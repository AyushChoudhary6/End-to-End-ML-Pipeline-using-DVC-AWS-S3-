{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6db33235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: wordcloud in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (1.9.4)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from wordcloud) (2.3.4)\n",
      "Requirement already satisfied: pillow in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from wordcloud) (11.3.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from wordcloud) (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib->wordcloud) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib->wordcloud) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib->wordcloud) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib->wordcloud) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib->wordcloud) (25.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib->wordcloud) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib->wordcloud) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: wordcloud in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (1.9.4)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from wordcloud) (2.3.4)\n",
      "Requirement already satisfied: pillow in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from wordcloud) (11.3.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from wordcloud) (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib->wordcloud) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib->wordcloud) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib->wordcloud) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib->wordcloud) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib->wordcloud) (25.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib->wordcloud) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib->wordcloud) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (3.9.2)\n",
      "Requirement already satisfied: click in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from nltk) (8.3.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from nltk) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from nltk) (2025.10.23)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (3.9.2)\n",
      "Requirement already satisfied: click in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from nltk) (8.3.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from nltk) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from nltk) (2025.10.23)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib\n",
    "%pip install wordcloud\n",
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c3e0b26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ayush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ayush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\ayush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing necessary libraries\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#importing wordcloud for text visualisation\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "#importing NLTK for natural language processing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords # for stopwords\n",
    "\n",
    "#downloading NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7b508b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read csv\n",
    "df = pd.read_csv('spam.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a000cf9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d9feb972",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['Unnamed: 2','Unnamed: 3','Unnamed: 4'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7d392bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename the columns\n",
    "df.rename(columns = {'v1':'target','v2':'text'},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f2ccd614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                               text\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94730de4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d00b9f2",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7ae5fd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (2.3.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0e5a2740",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "df['target'] = encoder.fit_transform(df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0fbad3ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0       0  Go until jurong point, crazy.. Available only ...\n",
       "1       0                      Ok lar... Joking wif u oni...\n",
       "2       1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       0  U dun say so early hor... U c already then say...\n",
       "4       0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e22a0eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(403)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check duplicate values\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eb6beae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e9aa3d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicate\n",
    "df = df.drop_duplicates(keep = 'first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2733ad",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "21b0d482",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing porter stemmer for text stemming\n",
    "\n",
    "from nltk.stem.porter  import PorterStemmer\n",
    "\n",
    "#importing the string module for handling special characters\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "66eedaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bf3e225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowercase transformation and text preprocessing function\n",
    "def transform_text(text):\n",
    "    #transform text to lowercase\n",
    "    text= text.lower()\n",
    "\n",
    "    #tokenization using nltk\n",
    "    text = nltk.word_tokenize(text)\n",
    "    \n",
    "    #removing special characters \n",
    "    y = []\n",
    "    for i in text:\n",
    "        if i.isalnum():\n",
    "            y.append(i)\n",
    "\n",
    "    #removing stop words and punctuations \n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "\n",
    "    #loop through the tokens and remove stopwords and punctuations\n",
    "    for i in text:\n",
    "        y.append(ps.stem(i))\n",
    "\n",
    "    #stemming using porter stemmer\n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "    \n",
    "    for i in text:\n",
    "        y.append(ps.stem(i))\n",
    "    \n",
    "    # Join the processed tokens back into a single string\n",
    "    return \" \".join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c2ecacb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go until jurong point crazi avail onli in bugi n great world la e buffet cine there got amor wat'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_text('Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cbacdbcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>transformed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go until jurong point crazi avail onli in bugi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joke wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entri in 2 a wkli comp to win fa cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say so earli hor u c alreadi then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah i do think he goe to usf he live around he...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text  \\\n",
       "0       0  Go until jurong point, crazy.. Available only ...   \n",
       "1       0                      Ok lar... Joking wif u oni...   \n",
       "2       1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3       0  U dun say so early hor... U c already then say...   \n",
       "4       0  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                    transformed_text  \n",
       "0  go until jurong point crazi avail onli in bugi...  \n",
       "1                              ok lar joke wif u oni  \n",
       "2  free entri in 2 a wkli comp to win fa cup fina...  \n",
       "3        u dun say so earli hor u c alreadi then say  \n",
       "4  nah i do think he goe to usf he live around he...  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['transformed_text'] = df['text'].apply(transform_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ce3558c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "tfid = TfidfVectorizer(max_features = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "02a8cf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfid.fit_transform(df['transformed_text']).toarray()\n",
    "y = df['target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d01de0a",
   "metadata": {},
   "source": [
    "Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4b898ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test , y_train, y_test = train_test_split(X,y,test_size = 0.20, random_state = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488579a2",
   "metadata": {},
   "source": [
    "\n",
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "26cfc87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-3.1.1-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from xgboost) (2.3.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\ayush\\appdata\\roaming\\python\\python313\\site-packages (from xgboost) (1.16.2)\n",
      "Downloading xgboost-3.1.1-py3-none-win_amd64.whl (72.0 MB)\n",
      "   ---------------------------------------- 0.0/72.0 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 6.8/72.0 MB 36.4 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 13.6/72.0 MB 34.7 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 15.5/72.0 MB 29.1 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 16.5/72.0 MB 21.7 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 18.1/72.0 MB 18.2 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 20.7/72.0 MB 17.0 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 24.1/72.0 MB 16.9 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 28.3/72.0 MB 17.4 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 30.4/72.0 MB 16.8 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 31.5/72.0 MB 15.5 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 32.8/72.0 MB 14.7 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 34.6/72.0 MB 14.1 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 36.7/72.0 MB 13.8 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 39.1/72.0 MB 13.7 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 41.4/72.0 MB 13.5 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 44.3/72.0 MB 13.5 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 48.0/72.0 MB 13.8 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 52.2/72.0 MB 14.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 57.4/72.0 MB 14.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 60.3/72.0 MB 14.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 62.9/72.0 MB 14.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 65.8/72.0 MB 14.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 69.5/72.0 MB 14.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  71.8/72.0 MB 14.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 72.0/72.0 MB 14.5 MB/s  0:00:04\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-3.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f570368b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a843283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel= \"sigmoid\", gamma  = 1.0)\n",
    "knc = KNeighborsClassifier()\n",
    "mnb = MultinomialNB()\n",
    "dtc = DecisionTreeClassifier(max_depth = 5)\n",
    "lrc = LogisticRegression(solver = 'liblinear', penalty = 'l1')\n",
    "rfc = RandomForestClassifier(n_estimators = 50, random_state = 2 )\n",
    "abc = AdaBoostClassifier(n_estimators = 50, random_state = 2)\n",
    "bc = BaggingClassifier(n_estimators = 50, random_state = 2)\n",
    "etc = ExtraTreesClassifier(n_estimators = 50, random_state = 2)\n",
    "gbdt = GradientBoostingClassifier(n_estimators = 50, random_state = 2)    \n",
    "xgb  = XGBClassifier(n_estimators = 50, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "56f34bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {\n",
    "    'SVC': svc,\n",
    "    'KNN': knc,\n",
    "    'NB': mnb,\n",
    "    'DT': dtc,\n",
    "    'LR': lrc,\n",
    "    'RF': rfc,\n",
    "    'Adaboost': abc,\n",
    "    'Bgc': bc,\n",
    "    'ETC': etc,\n",
    "    'GBDT': gbdt,\n",
    "    'xgb': xgb\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3ea90a",
   "metadata": {},
   "source": [
    "\n",
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "768fdc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "def train_classifier(clfs, X_train, y_train, X_test, y_test):\n",
    "    clfs.fit(X_train,y_train)\n",
    "    y_pred = clfs.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    return accuracy , precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0671a114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For:  SVC\n",
      "Accuracy:  0.9729206963249516\n",
      "Precision:  0.9661016949152542\n",
      "\n",
      "For:  KNN\n",
      "Accuracy:  0.9264990328820116\n",
      "Precision:  1.0\n",
      "\n",
      "For:  NB\n",
      "Accuracy:  0.9680851063829787\n",
      "Precision:  0.9646017699115044\n",
      "\n",
      "For:  DT\n",
      "Accuracy:  0.9361702127659575\n",
      "Precision:  0.8272727272727273\n",
      "\n",
      "For:  LR\n",
      "Accuracy:  0.9671179883945842\n",
      "Precision:  0.940677966101695\n",
      "\n",
      "For:  RF\n",
      "Accuracy:  0.9758220502901354\n",
      "Precision:  0.9669421487603306\n",
      "\n",
      "For:  Adaboost\n",
      "Accuracy:  0.9448742746615088\n",
      "Precision:  0.900990099009901\n",
      "\n",
      "For:  Bgc\n",
      "Accuracy:  0.9622823984526112\n",
      "Precision:  0.896\n",
      "\n",
      "For:  ETC\n",
      "Accuracy:  0.9758220502901354\n",
      "Precision:  0.9747899159663865\n",
      "\n",
      "For:  GBDT\n",
      "Accuracy:  0.9526112185686654\n",
      "Precision:  0.9405940594059405\n",
      "\n",
      "For:  xgb\n",
      "Accuracy:  0.9835589941972921\n",
      "Precision:  0.984\n"
     ]
    }
   ],
   "source": [
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "for name , clfs in clfs.items():\n",
    "    current_accuracy, current_precision = train_classifier(clfs, X_train, y_train, X_test, y_test)\n",
    "    print()\n",
    "    print(\"For: \", name)\n",
    "    print(\"Accuracy: \", current_accuracy)\n",
    "    print(\"Precision: \", current_precision)\n",
    "    \n",
    "    accuracy_scores.append(current_accuracy)\n",
    "    precision_scores.append(current_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00258bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
